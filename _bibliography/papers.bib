---
---

@misc{pitsillos2020intrinsic,
      abstract={We present an introspective framework inspired by the process of how humans perform 
                introspection. Our working assumption is that neural network activations encode 
                information, and building internal states from these activations can improve the 
                performance of an actor-critic model. We perform experiments where we first train 
                a Variational Autoencoder model to reconstruct the activations of a feature extraction 
                network and use the latent space to improve the performance of an actor-critic when deciding 
                which low-level robotic behaviour to execute. We show that internal states reduce the number of 
                episodes needed by about 1300 episodes while training an actor-critic, denoting faster convergence 
                to get a high success value while completing a robotic task.},
      title={Intrinsic Robotic Introspection: Learning Internal States From Neuron Activations}, 
      author={Nikos Pitsillos and Ameya Pore and Bjorn Sand Jensen and Gerardo Aragon-Camarasa},
      year={2020},
      eprint={2011.01880},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      code={https://github.com/cvas-ug/bbrl-introspection},
      selected={true}
}